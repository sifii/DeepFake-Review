Overview

This project involves distinguishing between human-generated reviews and reviews generated by Large Language Models (LLMs) using a multi-step process. The main steps are:

    Generating Synthetic Reviews: Using standard datasets (Amazon, IMDB) to create datasets of synthetic reviews.
    Fine-tuning BERT and GPT-3 Models: Fine-tuning BERT and GPT-3 models on the fake review dataset.
    Training a RoBERTa Model: Training a RoBERTa model to distinguish between human-generated and synthetic reviews.
    Model Comparison: Comparing the accuracy of different models, with the RoBERTa model achieving 95.4% accuracy on the IMDB dataset.

Steps
1. Generate Synthetic Reviews

Using standard datasets such as Amazon and IMDB, we create synthetic review datasets. The process involves:

    Amazon Cloths Review Dataset: Extracting and processing reviews from Amazon.
    IMDB Review Dataset: Extracting and processing movie reviews from IMDB.

2. Fine-tuning BERT and GPT-3 Models

    BERT Fine-tuning: Fine-tuning a BERT model on the fake review dataset to generate synthetic reviews.
    GPT-3 Fine-tuning: Fine-tuning a GPT-3 model on the fake review dataset to generate synthetic reviews.

3. Training RoBERTa Model

    RoBERTa Model Training: Training a RoBERTa model to distinguish between human-generated and synthetic reviews. The model is trained on a labeled dataset containing both human-generated and synthetic reviews.

4. Model Comparison

    Accuracy Comparison: Comparing the accuracy of different models on the IMDB dataset. The RoBERTa model achieves an accuracy of 95.4%.

Files

    Amazon_cloths_review.csv: Contains the Amazon cloths review dataset.
    IMDB_Review.csv: Contains the IMDB review dataset.
    Bert_Pretrained_Only_review.py: Python script for fine-tuning the BERT model on the fake review dataset.
    GPT2_Pretrained_only_review.csv: Contains the GPT-2 generated reviews.
    GPT_Pretrained_Only_review.py: Python script for fine-tuning the GPT-3 model on the fake review dataset.

How to Run

    Generate Synthetic Reviews:
        Process the Amazon and IMDB review datasets to create synthetic review datasets.

    Fine-tune BERT and GPT-3 Models:
        Run Bert_Pretrained_Only_review.py to fine-tune the BERT model.
        Run GPT_Pretrained_Only_review.py to fine-tune the GPT-3 model.

    Train RoBERTa Model:
        Train the RoBERTa model using the labeled dataset containing both human-generated and synthetic reviews.

    Compare Models:
        Evaluate the models on the IMDB dataset and compare their accuracies. The RoBERTa model should achieve an accuracy of 95.4%.

Results

The RoBERTa model trained to distinguish between human-generated and synthetic reviews achieved a high accuracy of 95.4% on the IMDB dataset, demonstrating its effectiveness in identifying fake reviews.
Conclusion

This project successfully demonstrates the use of LLMs to generate synthetic reviews and the ability of a RoBERTa model to distinguish between human-generated and synthetic reviews with high accuracy.
